{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fdf2e12",
   "metadata": {},
   "source": [
    "# Cái này là để cài đặt folder thành pakege để gọi imoport mà ko lỗi á. Nó tự sinh ra file 'signature_verification.egg-info' chứa thông tin tác giả của mìnhmình"
   ]
  },
  {
   "cell_type": "code",
   "id": "56ad7105",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T09:28:33.722202Z",
     "start_time": "2025-05-02T09:28:23.793227Z"
    }
   },
   "source": [
    "%cd ..\n",
    "\n",
    "# Cài đặt package\n",
    "!pip install -e .\n",
    "\n",
    "# Import module\n",
    "from utils.helpers import load_config\n",
    "from losses.contrastive_loss import ContrastiveLoss\n",
    "from models.siamese_network import SiameseNetwork\n",
    "\n",
    "print(\"Package installed and imported successfully!\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\PycharmProjects\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: file:///C:/Users/HP/PycharmProjects does not appear to be a Python project: neither 'setup.py' nor 'pyproject.toml' found.\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///C:/Users/HP/PycharmProjects\n",
      "Package installed and imported successfully!\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "930341a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T09:28:49.478949Z",
     "start_time": "2025-05-02T09:28:45.518399Z"
    }
   },
   "source": [
    "import os\n",
    "import yaml\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "01a21120",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T09:28:49.508009Z",
     "start_time": "2025-05-02T09:28:49.489597Z"
    }
   },
   "source": [
    "import random\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "\n",
    "class SiameseSignatureDataset(Dataset):\n",
    "    def __init__(self, org_dir, forg_dir, transform=None):\n",
    "        self.org_images = sorted([os.path.join(org_dir, f) for f in os.listdir(org_dir) if f.endswith('.png')])\n",
    "        self.forg_images = sorted([os.path.join(forg_dir, f) for f in os.listdir(forg_dir) if f.endswith('.png')])\n",
    "        self.transform = transform\n",
    "        self.pairs = self._create_pairs()\n",
    "\n",
    "    def _create_pairs(self):\n",
    "        pairs = []\n",
    "        # Tạo positive pairs (cùng người, chữ ký thật với thật)\n",
    "        for i in range(len(self.org_images)):\n",
    "            # Lấy 2 chữ ký khác nhau của cùng 1 người (dựa vào tên file)\n",
    "            base_name = os.path.basename(self.org_images[i]).split('_')[1]\n",
    "            matching = [img for img in self.org_images if f\"_{base_name}_\" in img]\n",
    "            if len(matching) > 1:\n",
    "                pairs.append((random.choice(matching), self.org_images[i], 1))  # Label 1 = similar\n",
    "\n",
    "        # Tạo negative pairs (chữ ký thật với giả hoặc khác người)\n",
    "        for i in range(len(self.org_images)):\n",
    "            # Chữ ký thật với giả của cùng người\n",
    "            base_name = os.path.basename(self.org_images[i]).split('_')[1]\n",
    "            forg_match = [img for img in self.forg_images if f\"_{base_name}_\" in img]\n",
    "            if forg_match:\n",
    "                pairs.append((self.org_images[i], random.choice(forg_match), 0))  # Label 0 = dissimilar\n",
    "\n",
    "            # Chữ ký của 2 người khác nhau\n",
    "            if i < len(self.org_images) - 1:\n",
    "                pairs.append((self.org_images[i], self.org_images[i+1], 0))\n",
    "\n",
    "        return pairs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img1_path, img2_path, label = self.pairs[idx]\n",
    "\n",
    "        img1 = Image.open(img1_path).convert('L')\n",
    "        img2 = Image.open(img2_path).convert('L')\n",
    "\n",
    "        if self.transform:\n",
    "            img1 = self.transform(img1)\n",
    "            img2 = self.transform(img2)\n",
    "\n",
    "        return (img1, img2), torch.tensor(label, dtype=torch.float32)"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T09:28:50.257786Z",
     "start_time": "2025-05-02T09:28:49.527424Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader\n",
    "# Transform chung\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((220, 150)),\n",
    "    transforms.Grayscale(),  # Đảm bảo ảnh 1 kênh\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: x.repeat(3, 1, 1)),  # 1 kênh -> 3 kênh\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# Tạo dataset\n",
    "siamese_dataset = SiameseSignatureDataset(\n",
    "    org_dir=r'C:\\Users\\HP\\PycharmProjects\\Deep_Learning-Based_Signature_Forgery_Detection_for_Personal_Identity_Authentication\\signatures\\full_org',\n",
    "    forg_dir=r'C:\\Users\\HP\\PycharmProjects\\Deep_Learning-Based_Signature_Forgery_Detection_for_Personal_Identity_Authentication\\signatures\\full_forg',\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "# Chia train/test\n",
    "train_size = int(0.8 * len(siamese_dataset))\n",
    "siamese_train, siamese_test = torch.utils.data.random_split(\n",
    "    siamese_dataset, [train_size, len(siamese_dataset) - train_size]\n",
    ")\n",
    "\n",
    "# Tạo DataLoader\n",
    "siamese_train_loader = DataLoader(siamese_train, batch_size=32, shuffle=True)\n",
    "siamese_test_loader = DataLoader(siamese_test, batch_size=32, shuffle=False)\n"
   ],
   "id": "cc02c9e576224b2d",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T09:28:50.411996Z",
     "start_time": "2025-05-02T09:28:50.292318Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Kiểm tra Siamese Dataset\n",
    "print(f\"Siamese Dataset - Total pairs: {len(siamese_dataset)}\")\n",
    "sample_pair, label = siamese_dataset[0]\n",
    "print(f\"Pair shape: {sample_pair[0].shape}, {sample_pair[1].shape}\")\n",
    "print(f\"Label: {label}\")"
   ],
   "id": "bc146528a222398e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Siamese Dataset - Total pairs: 3959\n",
      "Pair shape: torch.Size([3, 220, 150]), torch.Size([3, 220, 150])\n",
      "Label: 1.0\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "032a05e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T09:28:50.485285Z",
     "start_time": "2025-05-02T09:28:50.467970Z"
    }
   },
   "source": [
    "#Nayf ae xem sửa thửthử\n",
    "config = load_config(r'C:\\Users\\HP\\PycharmProjects\\Deep_Learning-Based_Signature_Forgery_Detection_for_Personal_Identity_Authentication\\configs\\config_siamese.yaml')\n",
    "print(config)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': {'backbone': 'resnet18', 'feature_dim': 512}, 'training': {'batch_size': 32, 'learning_rate': 0.001, 'optimizer': 'adam', 'num_epochs': 50, 'margin': 0.5, 'scheduler': 'cosine'}, 'dataset': {'train_data_path': './data/triplet/train/', 'val_data_path': './data/triplet/val/', 'input_size': '(220,150)'}, 'device': 'cuda', 'logging': {'log_dir': './logs/', 'checkpoint_dir': './checkpoints/', 'save_freq': 5}}\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "7c0b8fd8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T09:28:51.339491Z",
     "start_time": "2025-05-02T09:28:50.533939Z"
    }
   },
   "source": [
    "#Tiếp theo định nghĩa model từ con config\n",
    "model = SiameseNetwork(config['model']['backbone'], config['model']['feature_dim'])\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=config['training']['learning_rate'])\n",
    "device = torch.device(config['device'] if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\PycharmProjects\\Deep_Learning-Based_Signature_Forgery_Detection_for_Personal_Identity_Authentication\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\PycharmProjects\\Deep_Learning-Based_Signature_Forgery_Detection_for_Personal_Identity_Authentication\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SiameseNetwork(\n",
       "  (feature_extractor): ResNetFeatureExtractor(\n",
       "    (backbone): ResNet(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "      (fc): Identity()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "id": "bdd7a593",
   "metadata": {},
   "source": [
    "AE xem thử rồi cấu trúc ổn không."
   ]
  },
  {
   "cell_type": "code",
   "id": "ebb3217e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T09:38:34.510899Z",
     "start_time": "2025-05-02T09:32:00.470724Z"
    }
   },
   "source": [
    "from losses import contrastive_loss\n",
    "#Train kiểu kiểu như vầy ae cứ xem tham thảo\n",
    "\n",
    "num_epochs = config['training']['num_epochs']\n",
    "checkpoint_dir = config['logging']['checkpoint_dir']\n",
    "save_freq = config['logging']['save_freq']\n",
    "\n",
    "# Tạo thư mục lưu checkpoint nếu chưa có\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for (img1, img2), label in siamese_train_loader:\n",
    "        img1, img2 = img1.to(device), img2.to(device)\n",
    "        label = label.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        output1,output2 = model(img1,img2)\n",
    "\n",
    "        # Tính loss\n",
    "        loss = ContrastiveLoss()(output1, output2, label)\n",
    "\n",
    "        # Backward và optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    avg_loss = running_loss / len(siamese_train_loader)\n",
    "    print(f\"Epoch [{epoch}/{num_epochs}] - Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # === SAVE CHECKPOINT ===\n",
    "    if epoch % save_freq == 0:\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_epoch_{epoch}.pth')\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': avg_loss,\n",
    "        }, checkpoint_path)\n",
    "        print(f\"Checkpoint saved at {checkpoint_path}\")\n"
   ],
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[12]\u001B[39m\u001B[32m, line 27\u001B[39m\n\u001B[32m     25\u001B[39m \u001B[38;5;66;03m# Backward và optimize\u001B[39;00m\n\u001B[32m     26\u001B[39m optimizer.zero_grad()\n\u001B[32m---> \u001B[39m\u001B[32m27\u001B[39m \u001B[43mloss\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     28\u001B[39m optimizer.step()\n\u001B[32m     30\u001B[39m running_loss += loss.item()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Deep_Learning-Based_Signature_Forgery_Detection_for_Personal_Identity_Authentication\\.venv\\Lib\\site-packages\\torch\\_tensor.py:648\u001B[39m, in \u001B[36mTensor.backward\u001B[39m\u001B[34m(self, gradient, retain_graph, create_graph, inputs)\u001B[39m\n\u001B[32m    638\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m    639\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[32m    640\u001B[39m         Tensor.backward,\n\u001B[32m    641\u001B[39m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[32m   (...)\u001B[39m\u001B[32m    646\u001B[39m         inputs=inputs,\n\u001B[32m    647\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m648\u001B[39m \u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mautograd\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    649\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m=\u001B[49m\u001B[43minputs\u001B[49m\n\u001B[32m    650\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Deep_Learning-Based_Signature_Forgery_Detection_for_Personal_Identity_Authentication\\.venv\\Lib\\site-packages\\torch\\autograd\\__init__.py:353\u001B[39m, in \u001B[36mbackward\u001B[39m\u001B[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[39m\n\u001B[32m    348\u001B[39m     retain_graph = create_graph\n\u001B[32m    350\u001B[39m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[32m    351\u001B[39m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[32m    352\u001B[39m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m353\u001B[39m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    354\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    355\u001B[39m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    356\u001B[39m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    357\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    358\u001B[39m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    359\u001B[39m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    360\u001B[39m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    361\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Deep_Learning-Based_Signature_Forgery_Detection_for_Personal_Identity_Authentication\\.venv\\Lib\\site-packages\\torch\\autograd\\graph.py:824\u001B[39m, in \u001B[36m_engine_run_backward\u001B[39m\u001B[34m(t_outputs, *args, **kwargs)\u001B[39m\n\u001B[32m    822\u001B[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[32m    823\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m824\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mVariable\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_execution_engine\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[32m    825\u001B[39m \u001B[43m        \u001B[49m\u001B[43mt_outputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\n\u001B[32m    826\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[32m    827\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    828\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
