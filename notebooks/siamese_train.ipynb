{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fdf2e12",
   "metadata": {},
   "source": [
    "# Cái này là để cài đặt folder thành pakege để gọi imoport mà ko lỗi á. Nó tự sinh ra file 'signature_verification.egg-info' chứa thông tin tác giả của mìnhmình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56ad7105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Study\\School\\Phương pháp nghiên cứu\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Obtaining file:///D:/Study/School/Ph%C6%B0%C6%A1ng%20ph%C3%A1p%20nghi%C3%AAn%20c%E1%BB%A9u\n",
      "Package installed and imported successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.1\n",
      "[notice] To update, run: C:\\Users\\LEGION\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n",
      "ERROR: file:///D:/Study/School/Ph%C6%B0%C6%A1ng%20ph%C3%A1p%20nghi%C3%AAn%20c%E1%BB%A9u does not appear to be a Python project: neither 'setup.py' nor 'pyproject.toml' found.\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "\n",
    "# Cài đặt package\n",
    "!pip install -e .\n",
    "\n",
    "# Import module\n",
    "from utils.helpers import load_config\n",
    "from losses.contrastive_loss import contrastiveLoss\n",
    "from models.triplet_network import TripletNetwork\n",
    "from datasets import siamese_dataloader\n",
    "\n",
    "\n",
    "print(\"Package installed and imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e852e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pyyaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "930341a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import cv2\n",
    "import importlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "032a05e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': {'backbone': 'resnet34', 'feature_dim': 512}, 'training': {'batch_size': 32, 'learning_rate': 0.001, 'optimizer': 'adam', 'num_epochs': 50, 'margin': 0.5, 'scheduler': 'cosine'}, 'dataset': {'original_data_path': 'D:\\\\Study\\\\School\\\\Phương pháp nghiên cứu\\\\Deep_Learning-Based_Signature_Forgery_Detection_for_Personal_Identity_Authentication\\\\data\\\\full_org', 'forgeries_data_path': 'D:\\\\Study\\\\School\\\\Phương pháp nghiên cứu\\\\Deep_Learning-Based_Signature_Forgery_Detection_for_Personal_Identity_Authentication\\\\data\\\\full_forg', 'input_size': '(220,150)'}, 'device': 'cuda', 'logging': {'log_dir': './logs/', 'checkpoint_dir': './checkpoints/', 'save_freq': 5}}\n"
     ]
    }
   ],
   "source": [
    "#Nayf ae xem sửa thửthử\n",
    "config = load_config(r'D:\\Study\\School\\Phương pháp nghiên cứu\\Deep_Learning-Based_Signature_Forgery_Detection_for_Personal_Identity_Authentication\\configs\\config_siamese.yaml')\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d83c98a8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "If size is a sequence, it should have 1 or 2 values",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m importlib.reload(siamese_dataloader)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m train_loader, val_loader = \u001b[43msiamese_dataloader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_dataloaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Study\\School\\Phương pháp nghiên cứu\\Deep_Learning-Based_Signature_Forgery_Detection_for_Personal_Identity_Authentication\\datasets\\siamese_dataloader.py:185\u001b[39m, in \u001b[36mcreate_dataloaders\u001b[39m\u001b[34m(config)\u001b[39m\n\u001b[32m    182\u001b[39m img_size = \u001b[38;5;28mtuple\u001b[39m(config[\u001b[33m'\u001b[39m\u001b[33mdataset\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33minput_size\u001b[39m\u001b[33m'\u001b[39m]) \u001b[38;5;66;03m# (width, height)\u001b[39;00m\n\u001b[32m    184\u001b[39m \u001b[38;5;66;03m# Tạo transforms cho ảnh\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m185\u001b[39m transform = \u001b[43mget_transforms\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    187\u001b[39m \u001b[38;5;66;03m# Tạo dataset chung cho cả train và validation\u001b[39;00m\n\u001b[32m    188\u001b[39m full_dataset = SiameseDataset(\n\u001b[32m    189\u001b[39m     original_data_path=original_data_path,\n\u001b[32m    190\u001b[39m     forgeries_data_path=forgeries_data_path,\n\u001b[32m    191\u001b[39m     transform=transform\n\u001b[32m    192\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Study\\School\\Phương pháp nghiên cứu\\Deep_Learning-Based_Signature_Forgery_Detection_for_Personal_Identity_Authentication\\datasets\\siamese_dataloader.py:145\u001b[39m, in \u001b[36mget_transforms\u001b[39m\u001b[34m(img_size)\u001b[39m\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_transforms\u001b[39m(img_size):\n\u001b[32m    138\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    139\u001b[39m \u001b[33;03m    Tạo các biến đổi cho ảnh\u001b[39;00m\n\u001b[32m    140\u001b[39m \u001b[33;03m    \u001b[39;00m\n\u001b[32m    141\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m    142\u001b[39m \u001b[33;03m        img_size: tuple (width, height) - kích thước ảnh sau khi resize\u001b[39;00m\n\u001b[32m    143\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    144\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m transforms.Compose([\n\u001b[32m--> \u001b[39m\u001b[32m145\u001b[39m         \u001b[43mtransforms\u001b[49m\u001b[43m.\u001b[49m\u001b[43mResize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_size\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    146\u001b[39m         transforms.ToTensor(),\n\u001b[32m    147\u001b[39m         transforms.Normalize(mean=[\u001b[32m0.5\u001b[39m], std=[\u001b[32m0.5\u001b[39m])  \u001b[38;5;66;03m# Chuẩn hóa cho ảnh xám\u001b[39;00m\n\u001b[32m    148\u001b[39m     ])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:336\u001b[39m, in \u001b[36mResize.__init__\u001b[39m\u001b[34m(self, size, interpolation, max_size, antialias)\u001b[39m\n\u001b[32m    334\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSize should be int or sequence. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(size)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    335\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(size, Sequence) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(size) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m336\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mIf size is a sequence, it should have 1 or 2 values\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    337\u001b[39m \u001b[38;5;28mself\u001b[39m.size = size\n\u001b[32m    338\u001b[39m \u001b[38;5;28mself\u001b[39m.max_size = max_size\n",
      "\u001b[31mValueError\u001b[39m: If size is a sequence, it should have 1 or 2 values"
     ]
    }
   ],
   "source": [
    "importlib.reload(siamese_dataloader)\n",
    "train_loader, val_loader = siamese_dataloader.create_dataloaders(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0b8fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TripletNetwork(\n",
    "    backbone=config['model']['backbone'],\n",
    "    feature_dim=config['model']['feature_dim']\n",
    ")\n",
    "optimizer = optim.Adam(model.parameters(), lr=config['training']['learning_rate'])\n",
    "device = torch.device(config['device'] if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd7a593",
   "metadata": {},
   "source": [
    "AE xem thử rồi cấu trúc ổn không."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb3217e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train kiểu kiểu như vầy ae cứ xem tham thảo\n",
    "\n",
    "num_epochs = config['train']['num_epochs']\n",
    "checkpoint_dir = config['logging']['checkpoint_dir']\n",
    "save_freq = config['logging']['save_freq']\n",
    "\n",
    "# Tạo thư mục lưu checkpoint nếu chưa có\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for (img1, img2), labels in train_loader:\n",
    "        img1, img2, labels = img1.to(device), img2.to(device), labels.to(device)\n",
    "\n",
    "        output1 = model(img1)\n",
    "        output2 = model(img2)\n",
    "\n",
    "        loss = contrastiveLoss(output1, output2, labels, margin=config['loss']['margin'])\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    print(f\"Epoch [{epoch}/{num_epochs}] - Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    if epoch % save_freq == 0:\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_epoch_{epoch}.pth')\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': avg_loss,\n",
    "        }, checkpoint_path)\n",
    "        print(f\"Checkpoint saved at {checkpoint_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
