{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fdf2e12",
   "metadata": {},
   "source": [
    "# Cái này là để cài đặt folder thành pakege để gọi imoport mà ko lỗi á. Nó tự sinh ra file 'signature_verification.egg-info' chứa thông tin tác giả của mìnhmình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56ad7105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Project_Management\\Deep_Learning-Based_Signature_Forgery_Detection_for_Personal_Identity_Authentication\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\magics\\osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///D:/Project_Management/Deep_Learning-Based_Signature_Forgery_Detection_for_Personal_Identity_Authentication\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "INFO: pip is looking at multiple versions of signature-verification to determine which version is compatible with other requirements. This could take a while.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement pyymal (from signature-verification) (from versions: none)\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: No matching distribution found for pyymal\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package installed and imported successfully!\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "\n",
    "# Cài đặt package\n",
    "!pip install -e .\n",
    "\n",
    "# Import module\n",
    "from utils.helpers import load_config\n",
    "from losses.triplet_loss import tripletLoss\n",
    "from models.triplet_network import TripletNetwork\n",
    "\n",
    "print(\"Package installed and imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930341a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: d:\\\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yaml\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a21120",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data, bằng các lớp trong folder dataset, tui nghĩa nên làm 2 cái loader riêng cho 2 model do cấu trúc khác nhau\n",
    "#Triplet cần 3 ảnh anchor, positive, negative, vậy nên trong Loader sau khi load mỗi batch chứa 1 tuple 3 ảnh\n",
    "dataLloader = (1,2,3) #Tui viết cho có"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "032a05e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': {'backbone': 'resnet34', 'feature_dim': 512}, 'training': {'batch_size': 32, 'learning_rate': 0.001, 'optimizer': 'adam', 'num_epochs': 50, 'margin': 0.5, 'scheduler': 'cosine'}, 'dataset': {'train_data_path': './data/triplet/train/', 'val_data_path': './data/triplet/val/', 'input_size': '(220,150)'}, 'device': 'cuda', 'logging': {'log_dir': './logs/', 'checkpoint_dir': './checkpoints/', 'save_freq': 5}}\n"
     ]
    }
   ],
   "source": [
    "#Nayf ae xem sửa thửthử\n",
    "config = load_config(r'D:\\Project_Management\\Deep_Learning-Based_Signature_Forgery_Detection_for_Personal_Identity_Authentication\\configs\\config_triplet.yaml')\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0b8fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tiếp theo định nghĩa model từ con config\n",
    "model = TripletNetwork(config['model']['backbone'], config['model']['feature_dim'])\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=config['training']['learning_rate'])\n",
    "device = torch.device(config['device'] if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd7a593",
   "metadata": {},
   "source": [
    "AE xem thử rồi cấu trúc ổn không."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb3217e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train kiểu kiểu như vầy ae cứ xem tham thảo\n",
    "\n",
    "num_epochs = config['train']['num_epochs']\n",
    "checkpoint_dir = config['logging']['checkpoint_dir']\n",
    "save_freq = config['logging']['save_freq']\n",
    "\n",
    "# Tạo thư mục lưu checkpoint nếu chưa có\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for anchor, positive, negative in dataloader:\n",
    "        anchor, positive, negative = anchor.to(device), positive.to(device), negative.to(device)\n",
    "\n",
    "        anchor_feat, positive_feat, negative_feat = model(anchor, positive, negative)\n",
    "\n",
    "        loss = tripletLoss(anchor_feat, positive_feat, negative_feat, margin=config['loss']['margin']) \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    avg_loss = running_loss / len(dataloader)\n",
    "    print(f\"Epoch [{epoch}/{num_epochs}] - Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # === SAVE CHECKPOINT ===\n",
    "    if epoch % save_freq == 0:\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_epoch_{epoch}.pth')\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': avg_loss,\n",
    "        }, checkpoint_path)\n",
    "        print(f\"Checkpoint saved at {checkpoint_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
