{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fdf2e12",
   "metadata": {},
   "source": [
    "# Cái này là để cài đặt folder thành pakege để gọi imoport mà ko lỗi á. Nó tự sinh ra file 'signature_verification.egg-info' chứa thông tin tác giả của mìnhmình"
   ]
  },
  {
   "cell_type": "code",
   "id": "56ad7105",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T09:52:20.319969Z",
     "start_time": "2025-05-02T09:51:38.492078Z"
    }
   },
   "source": [
    "%cd ..\n",
    "\n",
    "# Cài đặt package\n",
    "!pip install -e .\n",
    "\n",
    "# Import module\n",
    "from utils.helpers import load_config\n",
    "from losses.triplet_loss import TripletLoss\n",
    "from models.triplet_network import TripletNetwork\n",
    "\n",
    "print(\"Package installed and imported successfully!\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\PycharmProjects\\Deep_Learning-Based_Signature_Forgery_Detection_for_Personal_Identity_Authentication\n",
      "Obtaining file:///C:/Users/HP/PycharmProjects/Deep_Learning-Based_Signature_Forgery_Detection_for_Personal_Identity_Authentication\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Checking if build backend supports build_editable: started\n",
      "  Checking if build backend supports build_editable: finished with status 'done'\n",
      "  Getting requirements to build editable: started\n",
      "  Getting requirements to build editable: finished with status 'done'\n",
      "  Preparing editable metadata (pyproject.toml): started\n",
      "  Preparing editable metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: pyyaml in c:\\users\\hp\\pycharmprojects\\deep_learning-based_signature_forgery_detection_for_personal_identity_authentication\\.venv\\lib\\site-packages (from signature_verification==0.1.0) (6.0.2)\n",
      "Requirement already satisfied: torch in c:\\users\\hp\\pycharmprojects\\deep_learning-based_signature_forgery_detection_for_personal_identity_authentication\\.venv\\lib\\site-packages (from signature_verification==0.1.0) (2.7.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\hp\\pycharmprojects\\deep_learning-based_signature_forgery_detection_for_personal_identity_authentication\\.venv\\lib\\site-packages (from signature_verification==0.1.0) (0.22.0)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\hp\\pycharmprojects\\deep_learning-based_signature_forgery_detection_for_personal_identity_authentication\\.venv\\lib\\site-packages (from signature_verification==0.1.0) (4.11.0.86)\n",
      "Requirement already satisfied: numpy in c:\\users\\hp\\pycharmprojects\\deep_learning-based_signature_forgery_detection_for_personal_identity_authentication\\.venv\\lib\\site-packages (from signature_verification==0.1.0) (2.2.5)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\hp\\pycharmprojects\\deep_learning-based_signature_forgery_detection_for_personal_identity_authentication\\.venv\\lib\\site-packages (from signature_verification==0.1.0) (3.10.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\hp\\pycharmprojects\\deep_learning-based_signature_forgery_detection_for_personal_identity_authentication\\.venv\\lib\\site-packages (from signature_verification==0.1.0) (1.6.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\hp\\pycharmprojects\\deep_learning-based_signature_forgery_detection_for_personal_identity_authentication\\.venv\\lib\\site-packages (from matplotlib->signature_verification==0.1.0) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\hp\\pycharmprojects\\deep_learning-based_signature_forgery_detection_for_personal_identity_authentication\\.venv\\lib\\site-packages (from matplotlib->signature_verification==0.1.0) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\hp\\pycharmprojects\\deep_learning-based_signature_forgery_detection_for_personal_identity_authentication\\.venv\\lib\\site-packages (from matplotlib->signature_verification==0.1.0) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\hp\\pycharmprojects\\deep_learning-based_signature_forgery_detection_for_personal_identity_authentication\\.venv\\lib\\site-packages (from matplotlib->signature_verification==0.1.0) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hp\\pycharmprojects\\deep_learning-based_signature_forgery_detection_for_personal_identity_authentication\\.venv\\lib\\site-packages (from matplotlib->signature_verification==0.1.0) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\hp\\pycharmprojects\\deep_learning-based_signature_forgery_detection_for_personal_identity_authentication\\.venv\\lib\\site-packages (from matplotlib->signature_verification==0.1.0) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\hp\\pycharmprojects\\deep_learning-based_signature_forgery_detection_for_personal_identity_authentication\\.venv\\lib\\site-packages (from matplotlib->signature_verification==0.1.0) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\hp\\pycharmprojects\\deep_learning-based_signature_forgery_detection_for_personal_identity_authentication\\.venv\\lib\\site-packages (from matplotlib->signature_verification==0.1.0) (2.9.0.post0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\hp\\pycharmprojects\\deep_learning-based_signature_forgery_detection_for_personal_identity_authentication\\.venv\\lib\\site-packages (from scikit-learn->signature_verification==0.1.0) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\hp\\pycharmprojects\\deep_learning-based_signature_forgery_detection_for_personal_identity_authentication\\.venv\\lib\\site-packages (from scikit-learn->signature_verification==0.1.0) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\hp\\pycharmprojects\\deep_learning-based_signature_forgery_detection_for_personal_identity_authentication\\.venv\\lib\\site-packages (from scikit-learn->signature_verification==0.1.0) (3.6.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\hp\\pycharmprojects\\deep_learning-based_signature_forgery_detection_for_personal_identity_authentication\\.venv\\lib\\site-packages (from torch->signature_verification==0.1.0) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\hp\\pycharmprojects\\deep_learning-based_signature_forgery_detection_for_personal_identity_authentication\\.venv\\lib\\site-packages (from torch->signature_verification==0.1.0) (4.13.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\hp\\pycharmprojects\\deep_learning-based_signature_forgery_detection_for_personal_identity_authentication\\.venv\\lib\\site-packages (from torch->signature_verification==0.1.0) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\hp\\pycharmprojects\\deep_learning-based_signature_forgery_detection_for_personal_identity_authentication\\.venv\\lib\\site-packages (from torch->signature_verification==0.1.0) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hp\\pycharmprojects\\deep_learning-based_signature_forgery_detection_for_personal_identity_authentication\\.venv\\lib\\site-packages (from torch->signature_verification==0.1.0) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\hp\\pycharmprojects\\deep_learning-based_signature_forgery_detection_for_personal_identity_authentication\\.venv\\lib\\site-packages (from torch->signature_verification==0.1.0) (2025.3.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hp\\pycharmprojects\\deep_learning-based_signature_forgery_detection_for_personal_identity_authentication\\.venv\\lib\\site-packages (from torch->signature_verification==0.1.0) (80.0.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\pycharmprojects\\deep_learning-based_signature_forgery_detection_for_personal_identity_authentication\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->signature_verification==0.1.0) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\hp\\pycharmprojects\\deep_learning-based_signature_forgery_detection_for_personal_identity_authentication\\.venv\\lib\\site-packages (from sympy>=1.13.3->torch->signature_verification==0.1.0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hp\\pycharmprojects\\deep_learning-based_signature_forgery_detection_for_personal_identity_authentication\\.venv\\lib\\site-packages (from jinja2->torch->signature_verification==0.1.0) (3.0.2)\n",
      "Building wheels for collected packages: signature_verification\n",
      "  Building editable for signature_verification (pyproject.toml): started\n",
      "  Building editable for signature_verification (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for signature_verification: filename=signature_verification-0.1.0-0.editable-py3-none-any.whl size=3181 sha256=85a979042ca655a13e86f46c0208e6442a6434fe8feaec44e759735b8d1f26dc\n",
      "  Stored in directory: C:\\Users\\HP\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-wtdzysyp\\wheels\\ac\\19\\f0\\44f2186c3f3dbf16f490f4a6e6b88a3297c41a7dacb40378a9\n",
      "Successfully built signature_verification\n",
      "Installing collected packages: signature_verification\n",
      "  Attempting uninstall: signature_verification\n",
      "    Found existing installation: signature_verification 0.1.0\n",
      "    Not uninstalling signature-verification at c:\\users\\hp\\pycharmprojects\\deep_learning-based_signature_forgery_detection_for_personal_identity_authentication, outside environment C:\\Users\\HP\\PycharmProjects\\Deep_Learning-Based_Signature_Forgery_Detection_for_Personal_Identity_Authentication\\.venv\n",
      "    Can't uninstall 'signature_verification'. No files were found to uninstall.\n",
      "Successfully installed signature_verification-0.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package installed and imported successfully!\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "930341a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T09:52:22.757639Z",
     "start_time": "2025-05-02T09:52:20.327005Z"
    }
   },
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T09:52:23.052181Z",
     "start_time": "2025-05-02T09:52:23.043899Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import random\n",
    "class TripletSignatureDataset(Dataset):\n",
    "    def __init__(self, org_dir, forg_dir, transform=None):\n",
    "        self.org_images = sorted([os.path.join(org_dir, f) for f in os.listdir(org_dir) if f.endswith('.png')])\n",
    "        self.forg_images = sorted([os.path.join(forg_dir, f) for f in os.listdir(forg_dir) if f.endswith('.png')])\n",
    "        self.transform = transform\n",
    "        self.triplets = self._create_triplets()\n",
    "\n",
    "    def _create_triplets(self):\n",
    "        triplets = []\n",
    "\n",
    "        # Tạo triplets với anchor là chữ ký thật\n",
    "        for anchor in self.org_images:\n",
    "            # Lấy base name (ví dụ: \"10\" từ \"original_10_1.png\")\n",
    "            base_name = os.path.basename(anchor).split('_')[1]\n",
    "\n",
    "            # Positive: chữ ký thật khác của cùng người\n",
    "            positives = [img for img in self.org_images\n",
    "                        if f\"_{base_name}_\" in img and img != anchor]\n",
    "\n",
    "            # Negative: chữ ký giả của cùng người hoặc chữ ký thật của người khác\n",
    "            forg_negatives = [img for img in self.forg_images if f\"_{base_name}_\" in img]\n",
    "            other_negatives = [img for img in self.org_images if f\"_{base_name}_\" not in img]\n",
    "            negatives = forg_negatives + other_negatives\n",
    "\n",
    "            if positives and negatives:\n",
    "                positive = random.choice(positives)\n",
    "                negative = random.choice(negatives)\n",
    "                triplets.append((anchor, positive, negative))\n",
    "\n",
    "        return triplets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.triplets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        anchor_path, positive_path, negative_path = self.triplets[idx]\n",
    "\n",
    "        anchor = Image.open(anchor_path).convert('L')\n",
    "        positive = Image.open(positive_path).convert('L')\n",
    "        negative = Image.open(negative_path).convert('L')\n",
    "\n",
    "        if self.transform:\n",
    "            anchor = self.transform(anchor)\n",
    "            positive = self.transform(positive)\n",
    "            negative = self.transform(negative)\n",
    "\n",
    "        return (anchor, positive, negative)"
   ],
   "id": "ec09341ad9ffac9e",
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "01a21120",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T09:52:23.911030Z",
     "start_time": "2025-05-02T09:52:23.062364Z"
    }
   },
   "source": [
    "# Transform chung\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((220, 150)),\n",
    "    transforms.Grayscale(),  # Đảm bảo ảnh 1 kênh xám\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: x.repeat(3, 1, 1)),  # 1 kênh -> 3 kênh\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "triplet_dataset = TripletSignatureDataset(\n",
    "    org_dir=r'C:\\Users\\HP\\PycharmProjects\\Deep_Learning-Based_Signature_Forgery_Detection_for_Personal_Identity_Authentication\\signatures\\full_org',\n",
    "    forg_dir=r'C:\\Users\\HP\\PycharmProjects\\Deep_Learning-Based_Signature_Forgery_Detection_for_Personal_Identity_Authentication\\signatures\\full_forg',\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "train_size = int(0.8 * len(triplet_dataset))\n",
    "triplet_train, triplet_test = torch.utils.data.random_split(\n",
    "    triplet_dataset, [train_size, len(triplet_dataset) - train_size]\n",
    ")\n",
    "\n",
    "triplet_train_loader = DataLoader(triplet_train, batch_size=32, shuffle=True)\n",
    "triplet_test_loader = DataLoader(triplet_test, batch_size=32, shuffle=False)"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "032a05e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T09:52:23.928760Z",
     "start_time": "2025-05-02T09:52:23.921364Z"
    }
   },
   "source": [
    "#Này ae xem sửa thử\n",
    "config = load_config(r'C:\\Users\\HP\\PycharmProjects\\Deep_Learning-Based_Signature_Forgery_Detection_for_Personal_Identity_Authentication\\configs\\config_triplet.yaml')\n",
    "print(config)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': {'backbone': 'resnet18', 'feature_dim': 512}, 'training': {'batch_size': 32, 'learning_rate': 0.001, 'optimizer': 'adam', 'num_epochs': 50, 'margin': 0.5, 'scheduler': 'cosine'}, 'dataset': {'train_data_path': './data/triplet/train/', 'val_data_path': './data/triplet/val/', 'input_size': '(220,150)'}, 'device': 'cuda', 'logging': {'log_dir': './logs/', 'checkpoint_dir': './checkpoints/', 'save_freq': 5}}\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "7c0b8fd8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T09:52:24.289324Z",
     "start_time": "2025-05-02T09:52:23.955613Z"
    }
   },
   "source": [
    "#Tiếp theo định nghĩa model từ con config\n",
    "model = TripletNetwork(config['model']['backbone'], config['model']['feature_dim'])\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=config['training']['learning_rate'])\n",
    "device = torch.device(config['device'] if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\PycharmProjects\\Deep_Learning-Based_Signature_Forgery_Detection_for_Personal_Identity_Authentication\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\PycharmProjects\\Deep_Learning-Based_Signature_Forgery_Detection_for_Personal_Identity_Authentication\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TripletNetwork(\n",
       "  (feature_extractor): ResNetFeatureExtractor(\n",
       "    (backbone): ResNet(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "      (fc): Identity()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "bdd7a593",
   "metadata": {},
   "source": [
    "AE xem thử rồi cấu trúc ổn không."
   ]
  },
  {
   "cell_type": "code",
   "id": "ebb3217e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T09:53:22.523390Z",
     "start_time": "2025-05-02T09:52:24.318115Z"
    }
   },
   "source": [
    "#Train kiểu kiểu như vầy ae cứ xem tham thảo\n",
    "\n",
    "num_epochs = config['training']['num_epochs']\n",
    "checkpoint_dir = config['logging']['checkpoint_dir']\n",
    "save_freq = config['logging']['save_freq']\n",
    "\n",
    "# Tạo thư mục lưu checkpoint nếu chưa có\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for anchor, positive, negative in triplet_train_loader:\n",
    "        anchor, positive, negative = anchor.to(device), positive.to(device), negative.to(device)\n",
    "\n",
    "        anchor_feat, positive_feat, negative_feat = model(anchor, positive, negative)\n",
    "\n",
    "        loss = TripletLoss()(anchor_feat, positive_feat, negative_feat)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    avg_loss = running_loss / len(triplet_train_loader)\n",
    "    print(f\"Epoch [{epoch}/{num_epochs}] - Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # === SAVE CHECKPOINT ===\n",
    "    if epoch % save_freq == 0:\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_epoch_{epoch}.pth')\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': avg_loss,\n",
    "        }, checkpoint_path)\n",
    "        print(f\"Checkpoint saved at {checkpoint_path}\")\n"
   ],
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[7]\u001B[39m\u001B[32m, line 17\u001B[39m\n\u001B[32m     14\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m anchor, positive, negative \u001B[38;5;129;01min\u001B[39;00m triplet_train_loader:\n\u001B[32m     15\u001B[39m     anchor, positive, negative = anchor.to(device), positive.to(device), negative.to(device)\n\u001B[32m---> \u001B[39m\u001B[32m17\u001B[39m     anchor_feat, positive_feat, negative_feat = \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43manchor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpositive\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnegative\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     19\u001B[39m     loss = TripletLoss()(anchor_feat, positive_feat, negative_feat)\n\u001B[32m     21\u001B[39m     optimizer.zero_grad()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Deep_Learning-Based_Signature_Forgery_Detection_for_Personal_Identity_Authentication\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Deep_Learning-Based_Signature_Forgery_Detection_for_Personal_Identity_Authentication\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Deep_Learning-Based_Signature_Forgery_Detection_for_Personal_Identity_Authentication\\models\\triplet_network.py:12\u001B[39m, in \u001B[36mTripletNetwork.forward\u001B[39m\u001B[34m(self, anchor, positive, negative)\u001B[39m\n\u001B[32m     11\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, anchor, positive, negative):\n\u001B[32m---> \u001B[39m\u001B[32m12\u001B[39m     anchor_feat = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mfeature_extractor\u001B[49m\u001B[43m(\u001B[49m\u001B[43manchor\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     13\u001B[39m     positive_feat = \u001B[38;5;28mself\u001B[39m.feature_extractor(positive)\n\u001B[32m     14\u001B[39m     negative_feat = \u001B[38;5;28mself\u001B[39m.feature_extractor(negative)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Deep_Learning-Based_Signature_Forgery_Detection_for_Personal_Identity_Authentication\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Deep_Learning-Based_Signature_Forgery_Detection_for_Personal_Identity_Authentication\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Deep_Learning-Based_Signature_Forgery_Detection_for_Personal_Identity_Authentication\\models\\feature_extractor.py:25\u001B[39m, in \u001B[36mResNetFeatureExtractor.forward\u001B[39m\u001B[34m(self, x)\u001B[39m\n\u001B[32m     24\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[32m---> \u001B[39m\u001B[32m25\u001B[39m     x = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mbackbone\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Output shape: (Batch, 512)\u001B[39;00m\n\u001B[32m     26\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m x\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Deep_Learning-Based_Signature_Forgery_Detection_for_Personal_Identity_Authentication\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Deep_Learning-Based_Signature_Forgery_Detection_for_Personal_Identity_Authentication\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Deep_Learning-Based_Signature_Forgery_Detection_for_Personal_Identity_Authentication\\.venv\\Lib\\site-packages\\torchvision\\models\\resnet.py:285\u001B[39m, in \u001B[36mResNet.forward\u001B[39m\u001B[34m(self, x)\u001B[39m\n\u001B[32m    284\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x: Tensor) -> Tensor:\n\u001B[32m--> \u001B[39m\u001B[32m285\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_forward_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Deep_Learning-Based_Signature_Forgery_Detection_for_Personal_Identity_Authentication\\.venv\\Lib\\site-packages\\torchvision\\models\\resnet.py:274\u001B[39m, in \u001B[36mResNet._forward_impl\u001B[39m\u001B[34m(self, x)\u001B[39m\n\u001B[32m    271\u001B[39m x = \u001B[38;5;28mself\u001B[39m.maxpool(x)\n\u001B[32m    273\u001B[39m x = \u001B[38;5;28mself\u001B[39m.layer1(x)\n\u001B[32m--> \u001B[39m\u001B[32m274\u001B[39m x = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mlayer2\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    275\u001B[39m x = \u001B[38;5;28mself\u001B[39m.layer3(x)\n\u001B[32m    276\u001B[39m x = \u001B[38;5;28mself\u001B[39m.layer4(x)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Deep_Learning-Based_Signature_Forgery_Detection_for_Personal_Identity_Authentication\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Deep_Learning-Based_Signature_Forgery_Detection_for_Personal_Identity_Authentication\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Deep_Learning-Based_Signature_Forgery_Detection_for_Personal_Identity_Authentication\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\container.py:240\u001B[39m, in \u001B[36mSequential.forward\u001B[39m\u001B[34m(self, input)\u001B[39m\n\u001B[32m    238\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[32m    239\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[32m--> \u001B[39m\u001B[32m240\u001B[39m         \u001B[38;5;28minput\u001B[39m = \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m    241\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Deep_Learning-Based_Signature_Forgery_Detection_for_Personal_Identity_Authentication\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Deep_Learning-Based_Signature_Forgery_Detection_for_Personal_Identity_Authentication\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Deep_Learning-Based_Signature_Forgery_Detection_for_Personal_Identity_Authentication\\.venv\\Lib\\site-packages\\torchvision\\models\\resnet.py:96\u001B[39m, in \u001B[36mBasicBlock.forward\u001B[39m\u001B[34m(self, x)\u001B[39m\n\u001B[32m     93\u001B[39m out = \u001B[38;5;28mself\u001B[39m.bn1(out)\n\u001B[32m     94\u001B[39m out = \u001B[38;5;28mself\u001B[39m.relu(out)\n\u001B[32m---> \u001B[39m\u001B[32m96\u001B[39m out = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mconv2\u001B[49m\u001B[43m(\u001B[49m\u001B[43mout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     97\u001B[39m out = \u001B[38;5;28mself\u001B[39m.bn2(out)\n\u001B[32m     99\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.downsample \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Deep_Learning-Based_Signature_Forgery_Detection_for_Personal_Identity_Authentication\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Deep_Learning-Based_Signature_Forgery_Detection_for_Personal_Identity_Authentication\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Deep_Learning-Based_Signature_Forgery_Detection_for_Personal_Identity_Authentication\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:554\u001B[39m, in \u001B[36mConv2d.forward\u001B[39m\u001B[34m(self, input)\u001B[39m\n\u001B[32m    553\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) -> Tensor:\n\u001B[32m--> \u001B[39m\u001B[32m554\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_conv_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Deep_Learning-Based_Signature_Forgery_Detection_for_Personal_Identity_Authentication\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:549\u001B[39m, in \u001B[36mConv2d._conv_forward\u001B[39m\u001B[34m(self, input, weight, bias)\u001B[39m\n\u001B[32m    537\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.padding_mode != \u001B[33m\"\u001B[39m\u001B[33mzeros\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m    538\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m F.conv2d(\n\u001B[32m    539\u001B[39m         F.pad(\n\u001B[32m    540\u001B[39m             \u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m._reversed_padding_repeated_twice, mode=\u001B[38;5;28mself\u001B[39m.padding_mode\n\u001B[32m   (...)\u001B[39m\u001B[32m    547\u001B[39m         \u001B[38;5;28mself\u001B[39m.groups,\n\u001B[32m    548\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m549\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[43m.\u001B[49m\u001B[43mconv2d\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    550\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mstride\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mdilation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mgroups\u001B[49m\n\u001B[32m    551\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
