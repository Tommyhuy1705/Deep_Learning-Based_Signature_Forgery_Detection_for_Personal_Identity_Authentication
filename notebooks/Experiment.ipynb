{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T13:43:29.313038Z",
     "iopub.status.busy": "2025-05-15T13:43:29.312732Z",
     "iopub.status.idle": "2025-05-15T13:43:41.086611Z",
     "shell.execute_reply": "2025-05-15T13:43:41.085913Z",
     "shell.execute_reply.started": "2025-05-15T13:43:29.313009Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'Deep_Learning-Based_Signature_Forgery_Detection_for_Personal_Identity_Authentication'...\n",
      "fatal: cannot write keep file 'C:/Users/duong/Downloads/Deep_Learning-Based_Signature_Forgery_Detection_for_Personal_Identity_Authentication/notebooks/Deep_Learning-Based_Signature_Forgery_Detection_for_Personal_Identity_Authentication/.git/objects/pack/pack-4fd7b959265ac910e8144e796cba75fed8d5928e.keep': Filename too long\n",
      "fatal: fetch-pack: invalid index-pack output\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/Tommyhuy1705/Deep_Learning-Based_Signature_Forgery_Detection_for_Personal_Identity_Authentication.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T13:43:41.088567Z",
     "iopub.status.busy": "2025-05-15T13:43:41.088283Z",
     "iopub.status.idle": "2025-05-15T13:43:41.094646Z",
     "shell.execute_reply": "2025-05-15T13:43:41.093941Z",
     "shell.execute_reply.started": "2025-05-15T13:43:41.088540Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 2] The system cannot find the file specified: 'Deep_Learning-Based_Signature_Forgery_Detection_for_Personal_Identity_Authentication'\n",
      "c:\\Users\\duong\\Downloads\\Deep_Learning-Based_Signature_Forgery_Detection_for_Personal_Identity_Authentication\\notebooks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\duong\\AppData\\Roaming\\Python\\Python313\\site-packages\\IPython\\core\\magics\\osm.py:393: UserWarning: This is now an optional IPython functionality, using bookmarks requires you to install the `pickleshare` library.\n",
      "  bkms = self.shell.db.get('bookmarks', {})\n"
     ]
    }
   ],
   "source": [
    "%cd Deep_Learning-Based_Signature_Forgery_Detection_for_Personal_Identity_Authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T13:43:41.095739Z",
     "iopub.status.busy": "2025-05-15T13:43:41.095462Z",
     "iopub.status.idle": "2025-05-15T13:44:53.869217Z",
     "shell.execute_reply": "2025-05-15T13:44:53.868492Z",
     "shell.execute_reply.started": "2025-05-15T13:43:41.095724Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///C:/Users/duong/Downloads/Deep_Learning-Based_Signature_Forgery_Detection_for_Personal_Identity_Authentication/notebooks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: file:///C:/Users/duong/Downloads/Deep_Learning-Based_Signature_Forgery_Detection_for_Personal_Identity_Authentication/notebooks does not appear to be a Python project: neither 'setup.py' nor 'pyproject.toml' found.\n"
     ]
    }
   ],
   "source": [
    "# Cài đặt package\n",
    "!pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T13:44:53.871791Z",
     "iopub.status.busy": "2025-05-15T13:44:53.871358Z",
     "iopub.status.idle": "2025-05-15T13:45:01.070490Z",
     "shell.execute_reply": "2025-05-15T13:45:01.069852Z",
     "shell.execute_reply.started": "2025-05-15T13:44:53.871768Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package installed and imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import module\n",
    "from utils.helpers import load_config, save_model, train_model, train_model_kfold\n",
    "from utils.model_evaluation import evaluate_model, draw_plot_evaluate, draw_plot_find_acc\n",
    "from models.Triplet_Siamese_Similarity_Network import tSSN\n",
    "from losses.triplet_loss import TripletLoss\n",
    "from dataloader.tSSN_trainloader import SignatureTrainDataset\n",
    "\n",
    "print(\"Package installed and imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T13:45:01.071495Z",
     "iopub.status.busy": "2025-05-15T13:45:01.071130Z",
     "iopub.status.idle": "2025-05-15T13:45:01.082364Z",
     "shell.execute_reply": "2025-05-15T13:45:01.081725Z",
     "shell.execute_reply.started": "2025-05-15T13:45:01.071475Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader,Subset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from PIL import Image\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#seed for reproducibility\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T13:45:01.083441Z",
     "iopub.status.busy": "2025-05-15T13:45:01.083070Z",
     "iopub.status.idle": "2025-05-15T13:45:01.691628Z",
     "shell.execute_reply": "2025-05-15T13:45:01.690807Z",
     "shell.execute_reply.started": "2025-05-15T13:45:01.083418Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Transform chung\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((220, 150)),\n",
    "    transforms.Grayscale(),  # Đảm bảo ảnh 1 kênh xám\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: x.repeat(3, 1, 1)),  # 1 kênh -> 3 kênh\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "dataset = SignatureTrainDataset(\n",
    "    org_dir=r'/kaggle/input/cedardataset/signatures/full_org',\n",
    "    forg_dir=r'/kaggle/input/cedardataset/signatures/full_forg',\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(\n",
    "    dataset, [train_size, len(dataset) - train_size]\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, num_workers=4, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, num_workers=4, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T13:45:01.692808Z",
     "iopub.status.busy": "2025-05-15T13:45:01.692550Z",
     "iopub.status.idle": "2025-05-15T13:45:01.833727Z",
     "shell.execute_reply": "2025-05-15T13:45:01.832963Z",
     "shell.execute_reply.started": "2025-05-15T13:45:01.692779Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Kiểm tra Triplet Dataset\n",
    "print(f\"Dataset - Total triplets: {len(dataset)}\")\n",
    "\n",
    "anchor, positive, negative = dataset[0]\n",
    "\n",
    "print(f\"Anchor shape: {anchor.shape}\")\n",
    "print(f\"Positive shape: {positive.shape}\")\n",
    "print(f\"Negative shape: {negative.shape}\")\n",
    "\n",
    "print(f\"Training dataset: {len(train_dataset)}\")\n",
    "\n",
    "anchor_train, positive_train, negative_train = train_dataset[0]\n",
    "\n",
    "print(f\"Anchor shape: {anchor_train.shape}\")\n",
    "print(f\"Positive shape: {positive_train.shape}\")\n",
    "print(f\"Negative shape: {negative_train.shape}\")\n",
    "\n",
    "print(f\"Testing dataset: {len(test_dataset)}\")\n",
    "\n",
    "anchor_test, positive_test, negative_test = test_dataset[0]\n",
    "\n",
    "print(f\"Anchor shape: {anchor_test.shape}\")\n",
    "print(f\"Positive shape: {positive_test.shape}\")\n",
    "print(f\"Negative shape: {negative_test.shape}\")\n",
    "\n",
    "print(\"LOAD DATASET SUCCESSFULLY\")\n",
    "print(f\"Train-Test Split Ratio: {len(train_dataset)/len(dataset)*100:.1f}% - {len(test_dataset)/len(dataset)*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T13:45:01.834706Z",
     "iopub.status.busy": "2025-05-15T13:45:01.834420Z",
     "iopub.status.idle": "2025-05-15T13:45:01.842225Z",
     "shell.execute_reply": "2025-05-15T13:45:01.841497Z",
     "shell.execute_reply.started": "2025-05-15T13:45:01.834665Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "config = load_config(r'/kaggle/working/Deep_Learning-Based_Signature_Forgery_Detection_for_Personal_Identity_Authentication/configs/config_tSSN.yaml')\n",
    "print(config)\n",
    "print(\"LOAD CONFIG SUCCESSFULLY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T13:45:01.843199Z",
     "iopub.status.busy": "2025-05-15T13:45:01.842943Z",
     "iopub.status.idle": "2025-05-15T15:44:54.481128Z",
     "shell.execute_reply": "2025-05-15T15:44:54.480297Z",
     "shell.execute_reply.started": "2025-05-15T13:45:01.843175Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "modes = ['euclidean', 'cosine', 'manhattan', 'learnable']\n",
    "margins = np.arange(0.2, 1.01, 0.2)\n",
    "\n",
    "results_dict:dict = {}\n",
    "\n",
    "for mode in modes:\n",
    "    if mode == 'learnable':\n",
    "        print(f\"\\nTraining mode: {mode} | margin: learnable\")\n",
    "\n",
    "        loss_fn = TripletLoss(\n",
    "                margin=margin,\n",
    "                mode=mode,\n",
    "                input_dim=config['model']['feature_dim']\n",
    "        )\n",
    "        \n",
    "        mean_acc, mean_loss = train_model_kfold(\n",
    "            config=config,\n",
    "            loss_fn=loss_fn,\n",
    "            dataset=train_dataset,\n",
    "            k_folds=10\n",
    "        )\n",
    "\n",
    "        results_dict[f\"{mode}\"] = {\n",
    "            'mean_acc': mean_acc,\n",
    "            'mean_loss': mean_loss\n",
    "        }\n",
    "    else:\n",
    "        for margin in margins:\n",
    "            print(f\"\\nTraining mode: {mode} | margin: {margin:.1f}\")\n",
    "                    \n",
    "            loss_fn = TripletLoss(\n",
    "                margin=margin,\n",
    "                mode=mode,\n",
    "                input_dim=config['model']['feature_dim']\n",
    "            )\n",
    "\n",
    "            mean_acc, mean_loss = train_model_kfold(\n",
    "                config=config,\n",
    "                loss_fn=loss_fn,\n",
    "                dataset=train_dataset,\n",
    "                k_folds=10\n",
    "            )\n",
    "            results_dict[f\"{mode}_{margin:.1f}\"] = {\n",
    "                'mean_acc': mean_acc,\n",
    "                'mean_loss': mean_loss\n",
    "            }   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ở đây lấy results_dict vẽ plot với y là mean_acc, x là key\n",
    "# xem model là tốt nhất\n",
    "# từ đó lấy ra best paremter \n",
    "# Viết hàm vẽ plot đó vào trong file utils/model_evaluation.py\n",
    "\n",
    "best_params = draw_plot_find_acc(results_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Block này sẽ train ra model cuối cùng với các tham số tốt nhất\n",
    "\n",
    "best_mode = best_params['mode']\n",
    "best_margin = best_params['margin']\n",
    "save_path = f\"/kaggle/working/final\"\n",
    "\n",
    "model = tSSN(config['model']['backbone'], config['model']['feature_dim'])\n",
    "device = torch.device(config['device'] if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = torch.nn.DataParallel(model, device_ids=[0, 1])\n",
    "\n",
    "loss_fn = TripletLoss(\n",
    "    margin=0 if best_mode == 'learnable' else best_margin,\n",
    "    mode=best_mode,\n",
    "    input_dim=config['model']['feature_dim']\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config['training']['learning_rate'])\n",
    "\n",
    "model, final_train_loss = train_model(\n",
    "    model=model,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    train_loader=train_loader,\n",
    "    num_epochs=config['training']['num_epochs'],\n",
    "    device=device,\n",
    "    early_stop=config['training']['early_stop']\n",
    ")\n",
    "\n",
    "# Lưu model\n",
    "save_model(model=model,\n",
    "        dir= save_path,     \n",
    "        optimizer=optimizer,\n",
    "        avg_loss=final_train_loss,\n",
    "        model_name=f\"tSNN_{best_mode}_{best_margin:.1f}\")\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đây sẽ là các block đánh giá các thông số của model cuối cùng, kèm theo đó là vẽ plot, cũng như test model\n",
    "# Hàm đánh giá tui để trong utils/model_evaluation.py tên hàm vẫn như cũ ae chỉ cần gọi là đc\n",
    "result = evaluate_model(model, best_mode, test_loader, device)\n",
    "\n",
    "draw_plot_evaluate(result, \"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T15:44:54.483950Z",
     "iopub.status.busy": "2025-05-15T15:44:54.483709Z",
     "iopub.status.idle": "2025-05-15T15:47:41.840187Z",
     "shell.execute_reply": "2025-05-15T15:47:41.839590Z",
     "shell.execute_reply.started": "2025-05-15T15:44:54.483929Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "kagglehub.login()\n",
    "\n",
    "kagglehub.model_upload(\n",
    "    handle=\"giahuytranviet/tSSN-verification-model/pyTorch/default\",\n",
    "    local_model_dir=\"/kaggle/working/final\",\n",
    "    version_notes=\"Upload latest model with best parameters\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 1512017,
     "sourceId": 2497231,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
